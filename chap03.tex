\chapter{A Estratégia Livre de Viés}
\label{cap:estrategia-livre-vies}

\section{Desafios atuais}
Conforme visto na seção \ref{sec:aprendizado-ativo}, as estratégias de Aprendizado Ativo (AA) sugiram face a dificuldade de se rotular de uma enorme quantidade de instâncias. As aplicações atuais estão gerando dados em velocidade e volume que seriam inimagináveis alguns poucos anos atrás. Este fenômeno, batizado de \textit{Big Data}, tem atraído a atenção da indústria, por seu valor econômico, e da academia, pelo desafio tecnológico que apresenta \citep{davenport_big_2014}.

Técnicas usuais de Aprendizado de Máquina (AM) supervisionado requerem um conjunto de treinamento devidamente rotulado em classes para que seja possível ``ensinar'' um modelo a reconhecer o padrão que distingue tais classes. Obviamente, quanto maior, mais balanceado e mais diversificado for o conjunto de treinamento, melhor será a acurácia do modelo. Entretanto, quando o volume de dados atinge a ordem de \textit{gigabytes} ou \textit{terabytes}, rotular tantas instâncias é um procedimento extremamente complicado, se não impossível.

Desta forma, uma possível solução é extrair uma amostra de tamanho muito menor, porém mantendo as principais propriedades estatísticas da base, e usá-la para o treinamento do modelo. Estratégias de AA poderiam ser facilmente empregadas a fim de se construir tal amostra, todavia, como as mesmas, em sua maioria, são baseadas em heurísticas, há um alto risco de se gerar amostras que não representam a base de maneira apropriada, ou seja, amostras enviesadas.

Com isto em mente, \citep{cadu:2013} propõe um método que busca extrair a amostra mais representativa possível a partir de uma enorme base de dados. Neste trabalho, adaptamos o método de \citep{cadu:2013} para atuar como uma estratégia de AA em Sistemas de Recomendação (SR) e a batizamos de \textit{Estratégia Livre de Viés}.

\section{O método genérico}
\label{sec:met-gen}
Seja $P$ um conjunto demasiadamente grande de instâncias pertencentes a um espaço vetorial $\mathbb{R}^k$. Assim, podemos assumir que a Função Densidade de Probabilidade (FDP) $\hat{p}$, estimada a partir de $P$, é uma boa estimativa da FDP populacional. Desejamos encontrar uma amostra $Q$, de tamanho muito menor que $P$ ($N_{Q} \ll N_{P}$), tal que a estimativa da FDP $\hat{q}$, feita a partir de $Q$, seja a mais próxima possível de $\hat{p}$.

Existem dois tipos de estimadores de FDP: paramétricos e não-paramétricos. Os primeiros buscam ajustar uma função paramétrica que representa a densidade dos dados, normalmente utilizando o Erro Médio Quadrático (EMQ) como indicador de aptidão \citep{degroot86stat}. Ou seja, quanto menor for o EMQ, mais apta é a função para representar a densidade dos dados. Obviamente, pode-se fazer o EMQ chegar a zero simplesmente ajustando os parâmetros para que a função passe por todos os pontos, caso conhecido com superespecialização. Além disso, caso não haja muitos dados disponíveis, pode-se acabar escolhendo uma função que destoa significativamente da FDP populacional.

Estimadores não-paramétricos, por sua vez, são mais apropriados quando há escassez de dados (propriedade que se espera para $Q$). Portanto, \citep{cadu:2013} faz a opção por estimar as FDPs através do estimador não-paramétrico conhecido como \textit{Kernel Density Estimator} (KDE). Tal estimador consiste basicamente em aplicar uma função \textit{kernel}, centrada em cada uma das instâncias da amostra, e tomar a média simples das mesmas como sendo a função que descreve a densidade dos dados \citep{Duda:2000:PC:954544}. 

Uma função \textit{kernel} é qualquer função cuja integral de menos infinito até infinito, em todas as dimensões, é igual a 1. Podemos citar como exemplo de função \textit{kernel} a função Gaussiana multivariada, dada através da equação \ref{eq:gauss-multi}, onde $x \in \mathbb{R}^k$, $\mu \in \mathbb{R}^k$, $det(\sigma)$ é o determinante da matriz de covariância e $\sigma^{-1}$ é a sua inversa. Em \citep{cadu:2013}, o autor faz a opção de usar, para o KDE, a função Gaussiana multivariada, assim $\hat{p}$ e $\hat{q}$ são dadas pelas equações \ref{eq:kde-of-q} e \ref{eq:kde-of-p}, respectivamente.

\begin{equation}
G(x, \mu, \sigma) = \frac{1}{\sqrt{det(\sigma) (2\pi)^k}} \exp \bigg( -\frac{1}{2} (x - \mu)^T \sigma^{-1} (x - \mu) \bigg)
\label{eq:gauss-multi}
\end{equation}

\begin{equation}
\hat{p}(x) = KDE(P) = \frac{1}{N_{P}} \sum_{i \in P} G(x, i, \sigma) 
\label{eq:kde-of-p}
\end{equation}

\begin{equation}
\hat{q}(x) = KDE(Q) = \frac{1}{N_{Q}} \sum_{i \in Q} G(x, i, \sigma) 
\label{eq:kde-of-q}
\end{equation}

Uma vez que se tenha em mãos as estimativas de FDP para ambas as amostras, é necessário saber o quão distante $\hat{q}$ está de $\hat{p}$. Na literatura, há diversas formas de mensurar a distância entre duas FDPs, conhecidas como \textit{divergentes} e habitualmente representadas através do símbolo $\Delta$. Como exemplo, podemos citar os divergentes Kullback–Leibler (equação \ref{eq:kl-div}), Cauchy-Schwarz (equação \ref{eq:cs-div}), \textit{Integrated Squared Error} (equação \ref{eq:ise-div}), entre outros. Calcula-se então a utilidade de cada instância em $P$, isto é, o quanto tal instância, se fosse inserida em $Q$, reduziria o divergente entre $\hat{p}$ e $\hat{q}$. A instância que deve ser inserida em $Q$ é aquela que mais promove a redução do divergente, ou seja, aquela com menor valor de utilidade. O algoritmo \ref{alg:proced-generico} apresenta o procedimento genérico para formação do conjunto $Q$, onde o critério de parada foi definido como sendo o numero de instâncias $\varepsilon$ em $Q$, mas também poderia ser o valor do divergente.

\begin{equation}
KL(\hat{p}, \hat{q}) = \int_{-\infty}^{\infty} \hat{p(x)} \log \frac{\hat{p}(x)}{\hat{q}(x)} \,\mathrm{d}x 
\label{eq:kl-div}
\end{equation}

\begin{equation}
CS(\hat{p}, \hat{q}) = -\log \frac{\int_{-\infty}^{\infty} \hat{p}(x)\hat{q}(x)\,\mathrm{d}x}{\sqrt{\int_{-\infty}^{\infty} [\hat{p}(x)]^2 \int_{-\infty}^{\infty} [\hat{q}(x)]^2\,\mathrm{d}x}}
\label{eq:cs-div}
\end{equation}

\begin{equation}
ISE(\hat{p}, \hat{q}) = \int_{-\infty}^{\infty} [\hat{p}(x) - \hat{q}(x)]^2 \,\mathrm{d}x
\label{eq:ise-div}
\end{equation}

\begin{algorithm}
\caption{Método genérico para formação do conjunto $Q$} 
\begin{algorithmic}[1]
\State{$\hat{p} \gets KDE(P)$}
\State{$Q \gets \emptyset$}
\While{$N_{Q} < \varepsilon$}
    \ForAll{$i \in P \setminus Q$}
        \State{$\hat{q} \gets KDE(Q \cup \{ i \})$}
        \State{$util(i) \gets \Delta(\hat{p}, \hat{q})$}
    \EndFor
    \State{$i' \gets \argmin_i util(i)$}
    \State{$Q \gets Q \cup \{ i' \}$}
\EndWhile
\end{algorithmic}
\label{alg:proced-generico}
\end{algorithm}

\section{Otimização do método}
Como é possível perceber, o procedimento descrito pelo algoritmo \ref{alg:proced-generico} funciona para qualquer tipo de divergente. Além disso, este procedimento também funcionaria para qualquer estimador de FDP, paramétrico ou não-paramétrico. Todavia, \citep{cadu:2013} mostra que, quando o KDE (com \textit{kernel} Gaussiano) é utilizado em conjunto com o divergente \textit{Integrated Squared Error} (ISE), isto acarreta num significativo ganho de desempenho.

Para tornarmos isto nítido ao leitor, substituiremos as fórmulas que descrevem $\hat{p}$ e $\hat{q}$ (equações \ref{eq:kde-of-p} e \ref{eq:kde-of-q}, respectivamente) na fórmula do ISE (equação \ref{eq:ise-div}). O resultado pode ser encontrado na equação \ref{eq:ise-com-kde}.

\begin{equation}
ISE(\hat{p}, \hat{q}) = \int_{-\infty}^{\infty} \left[\frac{1}{N_{P}} \sum_{i \in P} G(x, i, \sigma) - \frac{1}{N_{Q}} \sum_{j \in Q} G(x, j, \sigma)\right]^2 \, \mathrm{d}x 
\label{eq:ise-com-kde}
\end{equation}

Expandindo o produto notável, temos:

\begin{gather*}
\begin{split}
ISE(\hat{p}, \hat{q}) = \int_{-\infty}^{\infty} \Bigg[\left(\frac{1}{N_{P}} \sum_{i \in P} G(x, i, \sigma)\right)^2 - 2\left(\frac{1}{N_{P}} \sum_{i \in P} G(x, i, \sigma)\right)\left(\frac{1}{N_{Q}} \sum_{j \in Q} G(x, j, \sigma)\right) \\ + \left(\frac{1}{N_{Q}} \sum_{j \in Q} G(x, j, \sigma)\right)^2\Bigg] \,\mathrm{d}x
\end{split} \\
\begin{split}
ISE(\hat{p}, \hat{q}) = \int_{-\infty}^{\infty} \bigg[\frac{1}{{N_{P}}^2} \sum_{i \in P} \sum_{i' \in P} G(x, i, \sigma) G(x, i', \sigma) - \frac{2}{N_{P}N_{Q}} \sum_{i \in P} \sum_{j \in Q} G(x, i, \sigma) G(x, j, \sigma) \\
+ \frac{1}{{N_{Q}}^2} \sum_{j \in Q} \sum_{j' \in Q} G(x, j, \sigma) G(x, j', \sigma)\bigg] \, \mathrm{d}x 
\end{split}
\end{gather*}

Aplicando o teorema da convolução de Gaussianas, que nos diz que $\int G(x, \alpha, \sigma) G(x, \beta, \sigma) = G(\alpha, \beta, 2\sigma)$ \citep{Principe:2010:ITL:1855180}, temos:

\begin{gather*}
\begin{split}
ISE(\hat{p}, \hat{q}) = \frac{1}{{N_{P}}^2} \sum_{\substack{i \in P \\ i' \in P}} \left[\int_{-\infty}^{\infty} G(x, i, \sigma) G(x, i', \sigma) \, \mathrm{d}x\right] - \frac{2}{N_{P}N_{Q}} \sum_{\substack{i \in P \\ j \in Q}} \left[\int_{-\infty}^{\infty} G(x, i, \sigma) G(x, j, \sigma) \, \mathrm{d}x\right] \\
+ \frac{1}{{N_{Q}}^2} \sum_{\substack{j \in Q \\ j' \in Q}} \left[\int_{-\infty}^{\infty} G(x, j, \sigma) G(x, j', \sigma) \, \mathrm{d}x\right]
\end{split} \\
\begin{split}
ISE(\hat{p}, \hat{q}) = \frac{1}{{N_{P}}^2} \sum_{\substack{i \in P \\ i' \in P}} G(i, i', 2\sigma) - \frac{2}{N_{P}N_{Q}} \sum_{\substack{i \in P \\ j \in Q}} G(i, j, 2\sigma) + \frac{1}{{N_{Q}}^2} \sum_{\substack{j \in Q \\ j' \in Q}} G(j, j', 2\sigma)
\end{split}
\end{gather*}

Seja $\hat{q}^{(N_{Q})}$ a FDP calculada a partir do conjunto $Q$ contendo $N_{Q}$ instâncias, ou seja, $\hat{q}^{(N_{Q})}$ é dada através da equação \ref{eq:kde-of-q}. Seja $\gamma$ a melhor instância a se inserir em $Q$, isto é, aquela que resulta no menor ISE entre as duas FDPs. Ao inserirmos $\gamma$ em $Q$ e recalcularmos $\hat{q}$ agora com $N_{Q}+1$ instâncias, isto é, $\hat{q}^{(N_{Q}+1)}$, encontramos para $\hat{q}^{(N_{Q}+1)}$ e para $ISE(\hat{p}, \hat{q}^{(N_{Q}+1)})$ as equações \ref{eq:q-mais-um} e \ref{eq:ise-com-q-mais-um}, respectivamente.

\begin{equation}
\hat{q}^{(N_{Q}+1)} = \frac{1}{N_{Q}+1} \left[\left(\sum_{j \in Q \setminus \{ \gamma \}} G(x, j, \sigma)\right) + G(x, \gamma, \sigma)\right]
\label{eq:q-mais-um}
\end{equation}

\begin{equation}
\begin{split}
ISE(\hat{p}, \hat{q}^{(N_{Q}+1)}) = \frac{1}{{N_{P}}^2} \sum_{\substack{i \in P \\ i' \in P}} G(i, i', 2\sigma) - 2\frac{\sum_{i \in P} G(x, i, \sigma)}{N_{P}(N_{Q}+1)} \left[\sum_{j \in Q \setminus \{ \gamma \}} G(x, j, \sigma) + G(x, \gamma, \sigma)\right] \\ + \frac{1}{(N_{Q}+1)^2} \left[\sum_{j \in Q \setminus \{ \gamma \}} G(x, j, \sigma) + G(x, \gamma, \sigma)\right]^2
\end{split}
\label{eq:ise-com-q-mais-um}
\end{equation}

Expandindo o produto notável presente na equação \ref{eq:ise-com-q-mais-um}, temos:

\begin{gather*}
\begin{split}
ISE(\hat{p}, \hat{q}^{(N_{Q}+1)}) =  \frac{1}{{N_{P}}^2} \sum_{\substack{i \in P \\ i' \in P}} G(i, i', 2\sigma) - \frac{2}{N_{P}(N_{Q}+1)} \sum_{\substack{i \in P \\ j \in Q \setminus \{ \gamma \}}} G(i, j, 2\sigma) \\ -\frac{2}{N_{P}(N_{Q}+1)} \sum_{i \in P} G(i, \gamma, 2\sigma) + \frac{1}{(N_{Q}+1)^2} \sum_{\substack{j \in Q \setminus \{ \gamma \} \\ j' \in Q \setminus \{ \gamma \}}} G(j, j', 2\sigma) \\ + \frac{2}{(N_{Q}+1)^2} \sum_{j \in Q \setminus \{ \gamma \}} G(j, \gamma, 2\sigma) + \frac{1}{(N_{Q}+1)^2} G(\gamma, \gamma, 2\sigma)
\end{split}
\end{gather*}

Seja $V(\hat{p}, \hat{q})$ o Potencial de Informação \citep{Principe:2010:ITL:1855180} entre $\hat{p}$ e $\hat{q}$ dado através da equação \ref{eq:potencial-informacao}. Seja também $\pi$ a constante definida através da equação \ref{eq:constante-pi}. Desta forma, é possível reescrever $ISE(\hat{p}, \hat{q}^{(N_{Q}+1)})$ em termos de $V(\hat{p}, \hat{q})$ e $\pi$, conforme nos mostra a equação \ref{eq:expanding-ise}.

\begin{equation}
V(\hat{p}, \hat{q}) = \frac{1}{N_{P}N_{Q}} \sum_{\substack{i \in P \\ j \in Q \setminus \{ \gamma \} }} G(i, j, 2\sigma)
\label{eq:potencial-informacao}
\end{equation}

\begin{equation}
\pi = \frac{N_Q}{N_{Q}+1}
\label{eq:constante-pi}
\end{equation}

\begin{equation}
\begin{split}
ISE(\hat{p}, \hat{q}^{(N_{Q}+1)}) = V(\hat{p}, \hat{p}) - 2\pi V(\hat{p}, \hat{q}) - 2(1 - \pi) \frac{1}{N_P} \left(\sum_{i \in P} G(i, \gamma, 2\sigma)\right) \\ + \pi^{2}V(\hat{q}, \hat{q}) + 2\pi(1 - \pi) \frac{1}{N_Q} \left(\sum_{j \in Q \setminus \{ \gamma \}} G(j, \gamma, 2\sigma)\right) + (1 - \pi)^2 G(\gamma, \gamma, 2\sigma)
\end{split}
\label{eq:expanding-ise}
\end{equation}

De acordo com a definição do KDE, apresentada nas equações \ref{eq:kde-of-p} e \ref{eq:kde-of-q}, $\hat{p}(\gamma) = \frac{1}{N_P} \sum_{i \in P} G(i, \gamma, 2\sigma)$ e $\hat{q}(\gamma) = \frac{1}{N_Q} \sum_{j \in Q \setminus \{ \gamma \} } G(j, \gamma, 2\sigma)$. Além disso, $G(\gamma, \gamma, 2\sigma)$ é uma constante a qual nos referiremos como $\mathcal{K}$. Assim, renomeando e reorganizando as parcelas da equação \ref{eq:expanding-ise}, temos:

\begin{equation}
ISE(\hat{p}, \hat{q}^{(N_{Q}+1)}) = V(\hat{p}, \hat{p}) - 2\pi V(\hat{p}, \hat{q}) + \pi^{2}V(\hat{q}, \hat{q}) + (1 - \pi)^2 \mathcal{K} + 2(1 - \pi)\left[\pi \hat{q}(\gamma) - \hat{p}(\gamma)\right]
\label{eq:full-ise}
\end{equation}

Ou seja, para minimizar o ISE entre $\hat{p}$ e $\hat{q}$, basta escolher a instância $\gamma$ que minimiza a parcela $\pi \hat{q}(\gamma) - \hat{p}(\gamma)$, visto que as outras parcelas da equação \ref{eq:full-ise} são constantes. Este resultado representa um ganho computacional considerável, pois pode-se agora substituir o cálculo de $\hat{q}$, para cada instância, pela simples avaliação do valor de $\hat{q}$. Além disso, a atualização de $\hat{q}$ pode ser realizada através da equação \ref{eq:novo-q}, o que nos permite utilizar programação dinâmica.

\begin{equation}
\hat{q}^{(N_{Q}+1)} = \pi \hat{q}^{(N_{Q})} + (1 - \pi)G(x, \gamma, \sigma)
\label{eq:novo-q}
\end{equation}

\section{Adaptação do método para SR}
Mesmo com a otimização apresentada na seção anterior, ainda há uma enorme barreira na adaptação deste método para atuar como uma estratégia de AA em SR. Como estamos interessados em selecionar os itens que, se avaliados, trarão o maior ganho de desempenho para o sistema como um todo, as instâncias sobre as quais o método de \citep{cadu:2013} se baseia devem ser itens do SR.

Contudo, para que esses itens possam ser considerados instâncias, se faz necessário ter uma representação dos mesmos em um espaço vetorial $\mathbb{R}^k$, para que, a partir deste, seja possível calcular as devidas FDPs. Todavia, como a única informação que se tem sobre usuários e itens está presente na matriz de preferências, obter a representação vetorial dos mesmos não é uma tarefa trivial.

Conforme comentado na seção \ref{sec:svd}, a Decomposição em Valores Singulares (SVD) é uma ferramenta de extrema utilidade em SR, pois permite extrair, a partir da matriz de preferências, uma representação de usuários e itens em $k$ variáveis latentes, sendo o parâmetro $k$ arbitrário. Ou seja, aplicando o SVD na matriz de preferências, conseguimos representar os itens em um espaço $\mathbb{R}^k$ e, com isto, é possível identificar as regiões de maior densidade neste espaço através do KDE. No entanto, aplicar a decomposição SVD diretamente na matriz de preferências pode resultar uma representação que não é fiel a realidade do problema. 

É razoável assumir que uma avaliação presente na matriz de preferências retrata fielmente a preferência daquele usuário pelo item em questão. Entretanto, a ausência de uma avaliação levanta dúvidas quanto a preferência do usuário a respeito daquele item. A decomposição SVD, aplicada diretamente à matriz de preferências, assume que tais ausências correspondem a avaliações de valor zero, pois, como é um método numérico, necessita de uma matriz completamente preenchida. No entanto, esta suposição é perigosa, pois subentende que a grande maioria das preferências são do tipo mais baixo possível e isto pode refletir na representação vetorial de usuários e itens. 

Algumas abordagens foram propostas a fim de se realizar um pré-processamento na matriz de preferências antes que ela seja decomposta. Por exemplo, sugeriu-se preencher os valores faltantes com a média das notas do respectivo usuário; do respectivo item; ou ainda a média global do sistema. Porém, em todos esses casos, estamos introduzindo informações que podem destoar significativamente das preferências reais. Se, ao contrário, aplicarmos a decomposição na matriz binária, ao invés da matriz de preferências, temos certeza que os valores ali presentes realmente correspondem com a realidade do sistema. Ou seja, se $b_{ij} = 1$, temos certeza que o usuário $i$ adquiriu o item $j$. Caso contrário, temos certeza que $i$ não adquiriu o item $j$. Em suma, trabalhar com a matriz binária pode acarretar em perda das informações sobre as preferências, mas, em contrapartida, nos fornece a segurança de que não estamos introduzindo nenhum viés na representação vetorial.

Ainda sim, há restrições quanto aos itens que podem ser selecionados. Quando tratamos de \textit{Elicitação de Preferências para fins de Incentivo}, devemos ter em mente que há três tipos de itens: os que o usuário adquiriu e avaliou; os que o usuário adquiriu, porém não avaliou; e os que o usuário ainda não adquiriu. O método de \citep{cadu:2013} assume que todas as instâncias são passíveis de serem escolhidas, porém isto não é verdade em nosso contexto. Devemos restringir o método para selecionar somente os itens que o usuário adquiriu, mas não avaliou, pois não faz sentido selecionar itens de outros tipos neste contexto.

Desta forma, a \textit{Estratégia Livre de Viés} é dada através do algoritmo \ref{alg:estrategia-livre-vies}. Primeiramente, aplicamos a decomposição SVD na matriz binária $B$ e obtemos a matriz $U$ contento a representação dos usuários em $\mathbb{R}^k$; a matriz $V$ contento a representação dos itens em $\mathbb{R}^k$; e a matriz $\Sigma$ contento os valores singulares de $B$ (esta última não será utilizada, porém é um dos produtos da decomposição). Dado um usuário $i$, seja $K$ o grupo abrangendo os itens que $i$ adquiriu e avaliou e $X$ o grupo abrangendo os itens que $i$ adquiriu, porém não avaliou.

A estimativa $\hat{p}$ é dada através do KDE calculado sobre todos os itens e permanece inalterada durante todo o processo. Para cada usuário $i$, inicializamos a variável $L$, que armazenará os $N$ itens a serem solicitados, e calculamos a estimativa $\hat{q}$ com base no conjunto $K$. A partir de então, para cada item $j \in X$, calculamos e armazenamos sua utilidade através da fórmula apresentada na equação \ref{eq:full-ise}. Escolhemos portanto o item com menor valor de utilidade; inserimos o mesmo em $L$; recalculamos $\hat{q}$ com base na esquação \ref{eq:novo-q}; e repetimos o processo a fim de encontrarmos o segundo melhor item e assim sucessivamente até $L$ conter $N$ itens. Uma vez completa, resta-nos solicitar ao usuário $i$ que avalie os itens.

\begin{algorithm}
\caption{A Estratégia Livre de Viés} 
\begin{algorithmic}[1]
\State{$[U, \Sigma, V] \gets SVD(B, k)$}
\State{$\hat{p} \gets KDE(V, \sigma)$}
\ForAll{usuário $i \in U$}
    \State{$L \gets \emptyset$}
    \State{$\hat{q} \gets KDE(K, \sigma)$}
    \While{$|L| < N$}
        \ForAll{item $j \in X$}
            \State{$util(j) \gets \pi\hat{q}(j) - \hat{p}(j)$}
        \EndFor
        \State{$j' \gets \argmin_j util(j)$}
        \State{$L \gets L \cup \{ j' \}$}
        \State{$K \gets K \cup \{ j' \}$}
        \State{$X \gets X \setminus \{ j' \}$}
        \State{$\hat{q} \gets \pi \hat{q} + (1 - \pi)G(x, j', \sigma)$}
    \EndWhile
    \State{$i \xleftarrow{solicita} L$}
\EndFor
\end{algorithmic}
\label{alg:estrategia-livre-vies}
\end{algorithm}

\section{Escolha de parâmetros}
\label{sec:parametrizacao}

A \textit{Estratégia Livre de Viés} depende de apenas dois parâmetros: o numero de dimensões onde usuários e itens serão mapeados ($k$) e a matriz de covariância que será utilizada pelo KDE ($\sigma$), também conhecida como janela de Parzen \citep{Duda:2000:PC:954544}. 

Não há na literatura uma metodologia definida para a escolha de tais parâmetros. Portanto, escolhemos empiricamente, através diversos experimentos que seguiram a metodologia descrita no capítulo \ref{cap:metodologia}. Em outras palavras, várias versões da \textit{Estratégia Livre de Viés} foram comparadas, cada uma possuindo um valor específico para $k$ e $\sigma$. Ao final, optamos pela que apresentou melhor desempenho e acatamos seus parâmetros. Os testes comparando o desempenho desses parâmetros estão descritos na seção \ref{sec:escolha-parametros}.

É interessante notar que poderíamos ter utilizado valores de $\sigma$ distintos para as estimativas de $\hat{p}$ e $\hat{q}$. Fizemos a opção de utilizar o mesmo valor por motivos de simplicidade, afinal, usar $\sigma$'s diferentes tornaria a escolha de parâmetros ainda mais complicada. Como o objetivo deste trabalho é apresentar a \textit{Estratégia Livre de Viés} e provar que ela é uma boa opção para \textit{Elicitação de Preferências para fins de Incentivo}, deixamos as questões referentes ao ajuste fino para trabalhos futuros.

%$k=2$ e $\sigma = \bigl(\begin{smallmatrix} 0.00005&0\\ 0&0.00005 \end{smallmatrix} \bigr)$. Assim, quando apresentamos os resultados da \textit{Estratégia Livre de Viés} comparados com outras estratégias de AA, no capítulo \ref{cap:resultados}, nos referimos a \textit{Estratégia Livre de Viés} com tais parâmetros.