\begin{abstract}

Na literatura de Sistemas de Recomendação, estratégias de Aprendizado Ativo foram extensamente aplicadas à elicitação preferências para amenizar os efeitos do Arranque Frio, tarefa conhecida como \textit{Elicitação de Preferências para fins de Arranque Frio}. Contudo, se soubéssemos quais são os $N$ itens, dentre os já adquiridos mas não avaliados, que, se avaliados, trarão o maior ganho para o sistema em termos de acurácia, valeria a pena oferecer um incentivo para que o usuário avalie tais itens. A esta tarefa damos o nome de \textit{Elicitação de Preferência para fins de Incentivo}.

Este trabalho propõe uma nova estratégia de Aprendizado Ativo, que seleciona os itens com base na distribuição de probabilidade dos mesmos, gerando um conjunto de treinamento sem viés. A batizada \textit{Estratégia Livre de Viés} foi comparada com outras 16 estratégias populares dentro da literatura no que diz respeito a \textit{Elicitação de Preferência para fins de Incentivo}. A \textit{Estratégia Livre de Viés} mostrou desempenho superior as demais em termos de acurácia global do sistema. Além disso, apresentamos uma análise do comportamento de cada estratégia, levando em consideração os possíveis motivos de seu sucesso ou fracasso. 

\end{abstract}

